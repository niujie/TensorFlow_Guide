{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the SavedModel format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SavedModel from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tf.keras.utils.get_file(\n",
    "    \"grace_hopper.jpg\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\")\n",
    "img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = tf.keras.applications.mobilenet.preprocess_input(\n",
    "    x[tf.newaxis,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file(\n",
    "    'ImageNetLabels.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNet()\n",
    "result_before_save = pretrained_model(x)\n",
    "\n",
    "decoded = imagenet_labels[np.argsort(result_before_save)[0,::-1][:5]+1]\n",
    "\n",
    "print(\"Result before saving:\\n\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(pretrained_model, \"/tmp/mobilenet/1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /tmp/mobilenet/1 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(\"/tmp/mobilenet/1/\")\n",
    "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = infer(tf.constant(x))[pretrained_model.output_names[0]]\n",
    "\n",
    "decoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]\n",
    "\n",
    "print(\"Result after saving and loading:\\n\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a SavedModel in TensorFlow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=mobilenet \\\n",
    "  --model_base_path=\"/tmp/mobilenet\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q requests -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "import json\n",
    "import numpy\n",
    "import requests\n",
    "data = json.dumps({\"signature_name\": \"serving_default\",\n",
    "                   \"instances\": x.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/mobilenet:predict',\n",
    "                              data=data, headers=headers)\n",
    "predictions = numpy.array(json.loads(json_response.text)[\"predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SavedModel format on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/mobilenet/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /tmp/mobilenet/1 --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/mobilenet/1/variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModule(tf.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModule, self).__init__()\n",
    "        self.v = tf.Variable(1.)\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        return x * self.v\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "    def mutate(self, new_v):\n",
    "        self.v.assign(new_v)\n",
    "\n",
    "module = CustomModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module(tf.constant(0.))\n",
    "tf.saved_model.save(module, \"/tmp/module_no_signatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(\"/tmp/module_no_signatures\")\n",
    "assert 3. == imported(tf.constant(3.)).numpy()\n",
    "imported.mutate(tf.constant(2.))\n",
    "assert 6. == imported(tf.constant(3.)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported(tf.constant([3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.__call__.get_concrete_function(x=tf.TensorSpec([None], tf.float32))\n",
    "tf.saved_model.save(module, \"/tmp/module_no_signatures\")\n",
    "imported = tf.saved_model.load(\"/tmp/module_no_signatures\")\n",
    "assert [3.] == imported(tf.constant([3.])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /tmp/module_no_signatures --tag_set serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying a signature to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
    "tf.saved_model.save(module, \"/tmp/module_with_signature\", signatures=call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /tmp/module_with_signature --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(\"/tmp/module_with_signature\")\n",
    "signature = imported.signatures[\"serving_default\"]\n",
    "assert [3.] == signature(x=tf.constant([3.]))[\"output_0\"].numpy()\n",
    "imported.mutate(tf.constant(2.))\n",
    "assert [6.] == signature(x=tf.constant([3.]))[\"output_0\"].numpy()\n",
    "assert 2. == imported.v.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([], tf.string)])\n",
    "def parse_string(string_input):\n",
    "    return imported(tf.strings.to_number(string_input))\n",
    "\n",
    "signatures = {\"serving_default\": parse_string,\n",
    "              \"from_float\": imported.signatures[\"serving_default\"]}\n",
    "\n",
    "tf.saved_model.save(imported, \"/tmp/module_with_multiple_signatures\", signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /tmp/module_with_multiple_signatures --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli run --dir /tmp/module_with_multiple_signatures --tag_set serve --signature_def serving_default --input_exprs=\"string_input='3.'\"\n",
    "!saved_model_cli run --dir /tmp/module_with_multiple_signatures --tag_set serve --signature_def from_float --input_exprs=\"x=3.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing SavedModels in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(0.05)\n",
    "\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = (10. - imported(tf.constant(2.))) ** 2\n",
    "    variables = tape.watched_variables()\n",
    "    grads = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(grads, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    # \"v\" approaches 5, \"loss\" approaches 0\n",
    "    print(\"loss={:.2f} v={:.2f}\".format(train_step(), imported.v.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(\"/tmp/mobilenet/1/\")\n",
    "print(\"MobileNet has {} trainable variables: {}, ...\".format(\n",
    "          len(loaded.trainable_variables),\n",
    "          \", \".join([v.name for v in loaded.trainable_variables[:5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_variable_ids = {id(v) for v in loaded.trainable_variables}\n",
    "non_trainable_variables = [v for v in loaded.variables\n",
    "                           if id(v) not in trainable_variable_ids]\n",
    "print(\"MobileNet also has {} non-trainable variables: {}, ...\".format(\n",
    "          len(non_trainable_variables),\n",
    "          \", \".join([v.name for v in non_trainable_variables[:3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control flow in SavedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([], tf.int32)])\n",
    "def control_flow(x):\n",
    "    if x < 0:\n",
    "        tf.print(\"Invalid!\")\n",
    "    else:\n",
    "        tf.print(x % 3)\n",
    "\n",
    "to_export = tf.Module()\n",
    "to_export.control_flow = control_flow\n",
    "tf.saved_model.save(to_export, \"/tmp/control_flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(\"/tmp/control_flow\")\n",
    "imported.control_flow(tf.constant(-1))  # Invalid!\n",
    "imported.control_flow(tf.constant(2))   # 2\n",
    "imported.control_flow(tf.constant(3))   # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SavedModels from Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = tf.feature_column.numeric_column(\"x\")\n",
    "estimator = tf.estimator.LinearClassifier(feature_columns=[input_column])\n",
    "\n",
    "def input_fn():\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        ({\"x\": [1., 2., 3., 4.]}, [1, 1, 0, 0])).repeat(200).shuffle(64).batch(16)\n",
    "\n",
    "estimator.train(input_fn)\n",
    "\n",
    "serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "    tf.feature_column.make_parse_example_spec([input_column]))\n",
    "export_path = estimator.export_saved_model(\n",
    "    \"/tmp/from_estimator/\", serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(export_path)\n",
    "\n",
    "def predict(x):\n",
    "    example = tf.train.Example()\n",
    "    example.features.feature[\"x\"].float_list.value.extend([x])\n",
    "    return imported.signatures[\"predict\"](\n",
    "        examples=tf.constant([example.SerializeToString()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(1.5))\n",
    "print(predict(3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a SavedModel in C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C++\n",
    "const string export_dir = ...\n",
    "SavedModelBundle bundle;\n",
    "...\n",
    "LoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},\n",
    "               &bundle);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details of the SavedModel command line interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the SavedModel CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ bazel build tensorflow/python/tools:saved_model_cli\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *show* command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "usage: saved_model_cli show [-h] --dir DIR [--all]\n",
    "[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ saved_model_cli show --dir /tmp/saved_model_dir\n",
    "The given SavedModel contains the following tag-sets:\n",
    "serve\n",
    "serve, gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\n",
    "The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the\n",
    "following keys:\n",
    "SignatureDef key: \"classify_x2_to_y3\"\n",
    "SignatureDef key: \"classify_x_to_y\"\n",
    "SignatureDef key: \"regress_x2_to_y3\"\n",
    "SignatureDef key: \"regress_x_to_y\"\n",
    "SignatureDef key: \"regress_x_to_y2\"\n",
    "SignatureDef key: \"serving_default\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ saved_model_cli show --dir \\\n",
    "/tmp/saved_model_dir --tag_set serve --signature_def serving_default\n",
    "The given SavedModel SignatureDef contains the following input(s):\n",
    "  inputs['x'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 1)\n",
    "      name: x:0\n",
    "The given SavedModel SignatureDef contains the following output(s):\n",
    "  outputs['y'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 1)\n",
    "      name: y:0\n",
    "Method name is: tensorflow/serving/predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ saved_model_cli show --dir /tmp/saved_model_dir --all\n",
    "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
    "\n",
    "signature_def['classify_x2_to_y3']:\n",
    "  The given SavedModel SignatureDef contains the following input(s):\n",
    "    inputs['inputs'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: x2:0\n",
    "  The given SavedModel SignatureDef contains the following output(s):\n",
    "    outputs['scores'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: y3:0\n",
    "  Method name is: tensorflow/serving/classify\n",
    "\n",
    "...\n",
    "\n",
    "signature_def['serving_default']:\n",
    "  The given SavedModel SignatureDef contains the following input(s):\n",
    "    inputs['x'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: x:0\n",
    "  The given SavedModel SignatureDef contains the following output(s):\n",
    "    outputs['y'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 1)\n",
    "        name: y:0\n",
    "  Method name is: tensorflow/serving/predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *run* command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
    "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
    "                           [--input_exprs INPUT_EXPRS]\n",
    "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
    "                           [--overwrite] [--tf_debug]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--inputs <INPUTS>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "`<input_key>=[[1],[2],[3]]`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "`<input_key>=np.ones((32,32,3))`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "`<input_key>=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

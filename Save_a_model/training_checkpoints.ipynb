{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(tf.keras.Model):\n",
    "    \"\"\"A simple linear model.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(5)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving from tf.keras training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_weights('easy_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writting checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_dataset():\n",
    "    inputs = tf.range(10.)[:, None]\n",
    "    labels = inputs * 5. + tf.range(5.)[None, :]\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        dict(x=inputs, y=labels)).repeat(10).batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(net, example, optimizer):\n",
    "    \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = net(example['x'])\n",
    "        loss = tf.reduce_mean(tf.abs(output - example['y']))\n",
    "    variables = net.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the checkpoint objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and checkpoint the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_checkpoint(net, manager):\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    for example in toy_dataset():\n",
    "        loss = train_step(net, example, opt)\n",
    "        ckpt.step.assign_add(1)\n",
    "        if int(ckpt.step) % 10 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "            print(\"loss {:1.2f}\".format(loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "net = Net()\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "\n",
    "train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manager.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./tf_ckpts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_restore = tf.Variable(tf.zeros([5]))\n",
    "print(to_restore.numpy())  # All zeros\n",
    "fake_layer = tf.train.Checkpoint(bias=to_restore)\n",
    "fake_net = tf.train.Checkpoint(l1=fake_layer)\n",
    "new_root = tf.train.Checkpoint(net=fake_net)\n",
    "status = new_root.restore(tf.train.latest_checkpoint('./tf_ckpts/'))\n",
    "print(to_restore.numpy())  # We get the restored value now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status.assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed restorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_restore = tf.Variable(tf.zeros([1, 5]))\n",
    "print(delayed_restore.numpy())  # Not restored; still zeros\n",
    "fake_layer.kernel = delayed_restore\n",
    "print(delayed_restore.numpy())  # Restored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually inspecting checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.list_variables(tf.train.latest_checkpoint('./tf_ckpts/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and dictionary tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = tf.train.Checkpoint()\n",
    "save.listed = [tf.Variable(1.)]\n",
    "save.listed.append(tf.Variable(2.))\n",
    "save.mapped = {'one': save.listed[0]}\n",
    "save.mapped['two'] = save.listed[1]\n",
    "save_path = save.save('./tf_list_example')\n",
    "\n",
    "restore = tf.train.Checkpoint()\n",
    "v2 = tf.Variable(0.)\n",
    "assert 0. == v2.numpy()  # Not restored yet\n",
    "restore.mapped = {'two': v2}\n",
    "restore.restore(save_path)\n",
    "assert 2. == v2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore.listed = []\n",
    "print(restore.listed)  # ListWrapper([])\n",
    "v1 = tf.Variable(0.)\n",
    "restore.listed.append(v1)  # Restores v1, from restore() in the previous cell\n",
    "assert 1. == v1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving object-based checkpoints with Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf_compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    net = Net()\n",
    "    opt = tf.keras.optimizers.Adam(0.1)\n",
    "    ckpt = tf.train.Checkpoint(step=tf_compat.train.get_global_step(),\n",
    "                               optimizer=opt, net=net)\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = net(features['x'])\n",
    "        loss = tf.reduce_mean(tf.abs(output - features['y']))\n",
    "    variables = net.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode,\n",
    "        loss=loss,\n",
    "        train_op=tf.group(opt.apply_gradients(zip(gradients, variables)),\n",
    "                          ckpt.step.assign_add(1)),\n",
    "        # Tell the Estimator to save \"ckpt\" in an object-based format.\n",
    "        scaffold=tf_compat.train.Scaffold(saver=ckpt))\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "est = tf.estimator.Estimator(model_fn, './tf_estimator_example/')\n",
    "est.train(toy_dataset, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "net = Net()\n",
    "ckpt = tf.train.Checkpoint(\n",
    "  step=tf.Variable(1, dtype=tf.int64), optimizer=opt, net=net)\n",
    "ckpt.restore(tf.train.latest_checkpoint('./tf_estimator_example/'))\n",
    "ckpt.step.numpy()  # From est.train(..., steps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

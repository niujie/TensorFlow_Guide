{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better performance with the tf.data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtificialDataset(tf.data.Dataset):\n",
    "    def _generator(num_samples):\n",
    "        # Opening the file\n",
    "        time.sleep(0.03)\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            # Reading data (line, record) from the file\n",
    "            time.sleep(0.015)\n",
    "            \n",
    "            yield (sample_idx,)\n",
    "    \n",
    "    def __new__(cls, num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=tf.dtypes.int64,\n",
    "            output_shapes=(1,),\n",
    "            args=(num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(ArtificialDataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(ArtificialDataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(\n",
    "        ArtificialDataset,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_function(s):\n",
    "    # Do some hard pre-processing\n",
    "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .map(mapped_function)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .map(\n",
    "        mapped_function,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .map(  # Apply time consuming operations before cache\n",
    "        mapped_function\n",
    "    ).cache(\n",
    "    ),\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_dataset = tf.data.Dataset.range(10000)\n",
    "\n",
    "def fast_benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in tf.data.Dataset.range(num_epochs):\n",
    "        for _ in dataset:\n",
    "            pass\n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
    "    \n",
    "def increment(x):\n",
    "    return x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_benchmark(\n",
    "    fast_dataset\n",
    "    # Apply function one item at a time\n",
    "    .map(increment)\n",
    "    # Batch\n",
    "    .batch(256)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_benchmark(\n",
    "    fast_dataset\n",
    "    .batch(256)\n",
    "    # Apply function on a batch of items\n",
    "    # The tf.Tensor.__add__ method already handle batches\n",
    "    .map(increment)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing memory footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching partial computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dataset.map(time_consuming_mapping).cache().map(memory_consuming_mapping)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeMeasuredDataset(tf.data.Dataset):\n",
    "    # OUTPUT: (steps, timings, counters)\n",
    "    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)\n",
    "    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))\n",
    "    \n",
    "    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated\n",
    "    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset\n",
    "    \n",
    "    def _generator(instance_idx, num_samples):\n",
    "        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])\n",
    "        \n",
    "        # Opening the file\n",
    "        open_enter = time.perf_counter()\n",
    "        time.sleep(0.03)\n",
    "        open_elapsed = time.perf_counter() - open_enter\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            # Reading data (line, record) from the file\n",
    "            read_enter = time.perf_counter()\n",
    "            time.sleep(0.015)\n",
    "            read_elapsed = time.perf_counter() - read_enter\n",
    "            \n",
    "            yield (\n",
    "                [(\"Open\",), (\"Read\",)],\n",
    "                [(open_enter, open_elapsed), (read_enter, read_elapsed)],\n",
    "                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]\n",
    "            )\n",
    "            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered\n",
    "            \n",
    "    \n",
    "    def __new__(cls, num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=cls.OUTPUT_TYPES,\n",
    "            output_shapes=cls.OUTPUT_SHAPES,\n",
    "            args=(next(cls._INSTANCES_COUNTER), num_samples)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "(\n",
    "  [(\"Open\"), (\"Read\")],\n",
    "  [(t0, d), (t0, d)],\n",
    "  [(i, e, -1), (i, e, s)]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The iteration loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timelined_benchmark(dataset, num_epochs=2):\n",
    "    # Initialize accumulators\n",
    "    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)\n",
    "    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)\n",
    "    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        epoch_enter = time.perf_counter()\n",
    "        for (steps, times, values) in dataset:\n",
    "            # Record dataset preparation informations\n",
    "            steps_acc = tf.concat((steps_acc, steps), axis=0)\n",
    "            times_acc = tf.concat((times_acc, times), axis=0)\n",
    "            values_acc = tf.concat((values_acc, values), axis=0)\n",
    "            \n",
    "            # Simulate training time\n",
    "            train_enter = time.perf_counter()\n",
    "            time.sleep(0.01)\n",
    "            train_elapsed = time.perf_counter() - train_enter\n",
    "            \n",
    "            # Record training informations\n",
    "            steps_acc = tf.concat((steps_acc, [[\"Train\"]]), axis=0)\n",
    "            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)\n",
    "            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)\n",
    "        \n",
    "        epoch_elapsed = time.perf_counter() - epoch_enter\n",
    "        # Record epoch informations\n",
    "        steps_acc = tf.concat((steps_acc, [[\"Epoch\"]]), axis=0)\n",
    "        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)\n",
    "        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)\n",
    "        time.sleep(0.001)\n",
    "    \n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
    "    return {\"steps\": steps_acc, \"times\": times_acc, \"values\": values_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The plotting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_timeline(timeline, title, width=0.5, annotate=False, save=False):\n",
    "    # Remove invalid entries (negative times, or empty steps) from the timelines\n",
    "    invalid_mask = np.logical_and(timeline['times'] > 0, timeline['steps'] != b'')[:,0]\n",
    "    steps = timeline['steps'][invalid_mask].numpy()\n",
    "    times = timeline['times'][invalid_mask].numpy()\n",
    "    values = timeline['values'][invalid_mask].numpy()\n",
    "    \n",
    "    # Get a set of different steps, ordered by the first time they are encountered\n",
    "    step_ids, indices = np.stack(np.unique(steps, return_index=True))\n",
    "    step_ids = step_ids[np.argsort(indices)]\n",
    "\n",
    "    # Shift the starting time to 0 and compute the maximal time value\n",
    "    min_time = times[:,0].min()\n",
    "    times[:,0] = (times[:,0] - min_time)\n",
    "    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)\n",
    "    \n",
    "    cmap = mpl.cm.get_cmap(\"plasma\")\n",
    "    plt.close()\n",
    "    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={'hspace': 0})\n",
    "    fig.suptitle(title)\n",
    "    fig.set_size_inches(17.0, len(step_ids))\n",
    "    plt.xlim(-0.01, end)\n",
    "    \n",
    "    for i, step in enumerate(step_ids):\n",
    "        step_name = step.decode()\n",
    "        ax = axs[i]\n",
    "        ax.set_ylabel(step_name)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"time (s)\")\n",
    "        ax.set_xticklabels([])\n",
    "        ax.grid(which=\"both\", axis=\"x\", color=\"k\", linestyle=\":\")\n",
    "        \n",
    "        # Get timings and annotation for the given step\n",
    "        entries_mask = np.squeeze(steps==step)\n",
    "        serie = np.unique(times[entries_mask], axis=0)\n",
    "        annotations = values[entries_mask]\n",
    "        \n",
    "        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)\n",
    "        if annotate:\n",
    "            for j, (start, width) in enumerate(serie):\n",
    "                annotation = \"\\n\".join([f\"{l}: {v}\" for l,v in zip((\"i\", \"e\", \"s\"), annotations[j])])\n",
    "                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,\n",
    "                        horizontalalignment='left', verticalalignment='center')\n",
    "    if save:\n",
    "        plt.savefig(title.lower().translate(str.maketrans(\" \", \"_\")) + \".svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use wrappers for mapped function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decorator(func):\n",
    "    def wrapper(steps, times, values):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(\n",
    "            func,\n",
    "            inp=(steps, times, values),\n",
    "            Tout=(steps.dtype, times.dtype, values.dtype)\n",
    "        )\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_map_num_items = 50\n",
    "\n",
    "def dataset_generator_fun(*args):\n",
    "    return TimeMeasuredDataset(num_samples=_batch_map_num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@map_decorator\n",
    "def naive_map(steps, times, values):\n",
    "    map_enter = time.perf_counter()\n",
    "    time.sleep(0.001)  # Time contumming step\n",
    "    time.sleep(0.0001)  # Memory consumming step\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "\n",
    "    return (\n",
    "        tf.concat((steps, [[\"Map\"]]), axis=0),\n",
    "        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),\n",
    "        tf.concat((values, [values[-1]]), axis=0)\n",
    "    )\n",
    "\n",
    "naive_timeline = timelined_benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .flat_map(dataset_generator_fun)\n",
    "    .map(naive_map)\n",
    "    .batch(_batch_map_num_items, drop_remainder=True)\n",
    "    .unbatch(),\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@map_decorator\n",
    "def time_consumming_map(steps, times, values):\n",
    "    map_enter = time.perf_counter()\n",
    "    time.sleep(0.001 * values.shape[0])  # Time contumming step\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "\n",
    "    return (\n",
    "        tf.concat((steps, tf.tile([[[\"1st map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
    "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
    "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "@map_decorator\n",
    "def memory_consumming_map(steps, times, values):\n",
    "    map_enter = time.perf_counter()\n",
    "    time.sleep(0.0001 * values.shape[0])  # Memory consumming step\n",
    "    map_elapsed = time.perf_counter() - map_enter\n",
    "\n",
    "    # Use tf.tile to handle batch dimension\n",
    "    return (\n",
    "        tf.concat((steps, tf.tile([[[\"2nd map\"]]], [steps.shape[0], 1, 1])), axis=1),\n",
    "        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),\n",
    "        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "optimized_timeline = timelined_benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(  # Parallelize data reading\n",
    "        dataset_generator_fun,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(  # Vectorize your mapped function\n",
    "        _batch_map_num_items,\n",
    "        drop_remainder=True)\n",
    "    .map(  # Parallelize map transformation\n",
    "        time_consumming_map,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .cache()  # Cache data\n",
    "    .map(  # Reduce memory usage\n",
    "        memory_consumming_map,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .prefetch(  # Overlap producer and consumer works\n",
    "        tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .unbatch(),\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_timeline(naive_timeline, \"Naive\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_timeline(optimized_timeline, \"Optimized\", 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
